@article{rosenbaum1983,
    author = {ROSENBAUM, PAUL R. and RUBIN, DONALD B.},
    title = "{The central role of the propensity score in observational studies for causal effects}",
    journal = {Biometrika},
    volume = {70},
    number = {1},
    pages = {41-55},
    year = {1983},
    month = {04},
    abstract = "{The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two- dimensional plot.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/70.1.41},
    url = {https://doi.org/10.1093/biomet/70.1.41},
    eprint = {https://academic.oup.com/biomet/article-pdf/70/1/41/662954/70-1-41.pdf},
}

@article{rubin1974,
  title={Estimating causal effects of treatments in randomized and nonrandomized studies.},
  author={Donald B. Rubin},
  journal={Journal of Educational Psychology},
  year={1974},
  volume={66},
  pages={688-701}
}

@article{gpsboosting2015,
  title={A Boosting Algorithm for Estimating Generalized Propensity Scores with Continuous Treatments.},
  author={Zhu Y, Coffman DL, Ghosh D.},
  journal={Journal of Causal Inference},
  year={2015},
  volume={3(1)},
  pages={25-40},
  doi={10.1515/jci-2014-0022}
}

@article{angrist2018,
author = {Joshua D. Angrist and Òscar Jordà and Guido M. Kuersteiner},
title = {Semiparametric Estimates of Monetary Policy Effects: String Theory Revisited},
journal = {Journal of Business \& Economic Statistics},
volume = {36},
number = {3},
pages = {371-387},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/07350015.2016.1204919},

URL = { 
        https://doi.org/10.1080/07350015.2016.1204919
    
},
eprint = { 
        https://doi.org/10.1080/07350015.2016.1204919
    
}
,
    abstract = { We develop flexible semiparametric time series methods for the estimation of the causal effect of monetary policy on macroeconomic aggregates. Our estimator captures the average causal response to discrete policy interventions in a macrodynamic setting, without the need for assumptions about the process generating macroeconomic outcomes. The proposed estimation strategy, based on propensity score weighting, easily accommodates asymmetric and nonlinear responses. Using this estimator, we show that monetary tightening has clear effects on the yield curve and on economic activity. Monetary accommodation, however, appears to generate less pronounced responses from both. Estimates for recent financial crisis years display a similarly dampened response to monetary accommodation. }
}

@article{holland1986,
author = { Paul W.   Holland },
title = {Statistics and Causal Inference},
journal = {Journal of the American Statistical Association},
volume = {81},
number = {396},
pages = {945-960},
year  = {1986},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1986.10478354},

URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478354
    
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1986.10478354
    
}

}

@article {hirano2004,
	title = {The Propensity Score with Continuous Treatments},
	year = {2004},
	author = {Guido Imbens and Keisuke Hirano}
}

@article{mbb1989,
author = {Hans R. Kunsch},
title = {{The Jackknife and the Bootstrap for General Stationary Observations}},
volume = {17},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1217 -- 1241},
abstract = {We extend the jackknife and the bootstrap method of estimating standard errors to the case where the observations form a general stationary sequence. We do not attempt a reduction to i.i.d. values. The jackknife calculates the sample variance of replicates of the statistic obtained by omitting each block of $l$ consecutive data once. In the case of the arithmetic mean this is shown to be equivalent to a weighted covariance estimate of the spectral density of the observations at zero. Under appropriate conditions consistency is obtained if $l = l(n) \rightarrow \infty$ and $l(n)/n \rightarrow 0$. General statistics are approximated by an arithmetic mean. In regular cases this approximation determines the asymptotic behavior. Bootstrap replicates are constructed by selecting blocks of length $l$ randomly with replacement among the blocks of observations. The procedures are illustrated by using the sunspot numbers and some simulated data.},
keywords = {bootstrap, influence function, jackknife, statistics defined by functionals, time series, variance estimation},
year = {1989},
doi = {10.1214/aos/1176347265},
URL = {https://doi.org/10.1214/aos/1176347265}
}

@article{imbens2000,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2673642},
 abstract = {Estimation of average treatment effects in observational studies often requires adjustment for differences in pre-treatment variables. If the number of pre-treatment variables is large, standard covariance adjustment methods are often inadequate. Rosenbaum & Rubin (1983) propose an alternative method for adjusting for pre-treatment variables for the binary treatment case based on the so-called propensity score. Here an extension of the propensity score methodology is proposed that allows for estimation of average casual effects with multi-valued treatments.},
 author = {Guido W. Imbens},
 journal = {Biometrika},
 number = {3},
 pages = {706--710},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {The Role of the Propensity Score in Estimating Dose-Response Functions},
 urldate = {2022-09-26},
 volume = {87},
 year = {2000}
}

@article{zivich2022,
  doi = {10.48550/ARXIV.2207.05010},
  
  url = {https://arxiv.org/abs/2207.05010},
  
  author = {Zivich, Paul N and Cole, Stephen R and Westreich, Daniel},
  
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Positivity: Identifiability and Estimability},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{quasipoisson,
    author = {WEDDERBURN, R. W. M.},
    title = "{Quasi-likelihood functions, generalized linear models, and the Gauss—Newton method}",
    journal = {Biometrika},
    volume = {61},
    number = {3},
    pages = {439-447},
    year = {1974},
    month = {12},
    abstract = "{To define a likelihood we have to specify the form of distribution of the observations, but to define a quasi-likelihood function we need only specify a relation between the mean and variance of the observations and the quasi-likelihood can then be used for estimation. For a one-parameter exponential family the log likelihood is the same as the quasi-likelihood and it follows that assuming a one-parameter exponential family is the weakest sort of distributional assumption that can be made. The Gauss-Newton method for calculating nonlinear least squares estimates generalizes easily to deal with maximum quasi-likelihood estimates, and a rearrangement of this produces a generalization of the method described by Nelder \\&amp; Wedderburn (1972).}",
    issn = {0006-3444},
    doi = {10.1093/biomet/61.3.439},
    url = {https://doi.org/10.1093/biomet/61.3.439},
    eprint = {https://academic.oup.com/biomet/article-pdf/61/3/439/690500/61-3-439.pdf},
}

@ARTICLE{dlnm2010R,
  title    = "Distributed lag linear and non-linear models in R: The package
              dlnm",
  author   = "Gasparrini, Antonio",
  abstract = "Distributed lag non-linear models (DLNMs) represent a modeling
              framework to flexibly describe associations showing potentially
              non-linear and delayed effects in time series data. This
              methodology rests on the definition of a crossbasis, a
              bi-dimensional functional space expressed by the combination of
              two sets of basis functions, which specify the relationships in
              the dimensions of predictor and lags, respectively. This
              framework is implemented in the R package dlnm, which provides
              functions to perform the broad range of models within the DLNM
              family and then to help interpret the results, with an emphasis
              on graphical representation. This paper offers an overview of the
              capabilities of the package, describing the conceptual and
              practical steps to specify and interpret DLNMs with an example of
              application to real data.",
  journal  = "J. Stat. Softw.",
  volume   =  43,
  number   =  8,
  pages    = "1--20",
  month    =  jul,
  year     =  2011,
  language = "en"
}

@article{dlnm2010,
author = {Gasparrini, A. and Armstrong, B. and Kenward, M. G.},
title = {Distributed lag non-linear models},
journal = {Statistics in Medicine},
volume = {29},
number = {21},
pages = {2224-2234},
keywords = {distributed lag, time series, smoothing, delayed effects},
doi = {https://doi.org/10.1002/sim.3940},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3940},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.3940},
abstract = {Abstract Environmental stressors often show effects that are delayed in time, requiring the use of statistical models that are flexible enough to describe the additional time dimension of the exposure–response relationship. Here we develop the family of distributed lag non-linear models (DLNM), a modelling framework that can simultaneously represent non-linear exposure–response dependencies and delayed effects. This methodology is based on the definition of a ‘cross-basis’, a bi-dimensional space of functions that describes simultaneously the shape of the relationship along both the space of the predictor and the lag dimension of its occurrence. In this way the approach provides a unified framework for a range of models that have previously been used in this setting, and new more flexible variants. This family of models is implemented in the package dlnm within the statistical environment R. To illustrate the methodology we use examples of DLNMs to represent the relationship between temperature and mortality, using data from the National Morbidity, Mortality, and Air Pollution Study (NMMAPS) for New York during the period 1987–2000. Copyright © 2010 John Wiley \& Sons, Ltd.},
year = {2010}
}

@article{wu2020sciadv,
author = {X. Wu  and D. Braun  and J. Schwartz  and M. A. Kioumourtzoglou  and F. Dominici },
title = {Evaluating the impact of long-term exposure to fine particulate matter on mortality among the elderly},
journal = {Science Advances},
volume = {6},
number = {29},
pages = {eaba5692},
year = {2020},
doi = {10.1126/sciadv.aba5692},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.aba5692},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.aba5692},
abstract = {Long-term exposure to fine particulate matter positively affects all-cause mortality among the elderly. Many studies link long-term fine particle (PM2.5) exposure to mortality, even at levels below current U.S. air quality standards (12 micrograms per cubic meter). These findings have been disputed with claims that the use of traditional statistical approaches does not guarantee causality. Leveraging 16 years of data—68.5 million Medicare enrollees—we provide strong evidence of the causal link between long-term PM2.5 exposure and mortality under a set of causal inference assumptions. Using five distinct approaches, we found that a decrease in PM2.5 (by 10 micrograms per cubic meter) leads to a statistically significant 6 to 7\% decrease in mortality risk. Based on these models, lowering the air quality standard to 10 micrograms per cubic meter would save 143,257 lives (95\% confidence interval, 115,581 to 170,645) in one decade. Our study provides the most comprehensive evidence to date of the link between long-term PM2.5 exposure and mortality, even at levels below current standards.}}

@article{bojinov2019,
author = {Iavor Bojinov and Neil Shephard},
title = {Time Series Experiments and Causal Estimands: Exact Randomization Tests and Trading},
journal = {Journal of the American Statistical Association},
volume = {114},
number = {528},
pages = {1665-1682},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2018.1527225},
URL = { 
        https://doi.org/10.1080/01621459.2018.1527225
},
eprint = { 
        https://doi.org/10.1080/01621459.2018.1527225
}
}





